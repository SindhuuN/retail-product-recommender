# -*- coding: utf-8 -*-
"""recommendationsystem.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oxdgriwbDkf0h-HQwvGB1Azg5j1RBlQu

Load necessary libraries
"""

# Basics
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
plt.style.use("ggplot")

# Scikit-learn utilities
from sklearn.decomposition import TruncatedSVD
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Sparse matrix
from scipy.sparse import coo_matrix

# For visualization (optional)
import seaborn as sns

# For evaluation (optional)
from sklearn.metrics import precision_score, recall_score

# For saving and loading models (optional)
import pickle


# Warnings
import warnings
warnings.filterwarnings("ignore")
!pip install scikit-surprise


"""Load the datasets

"""

events = pd.read_csv('sampled_events.csv')
item_props1 = pd.read_csv('sampled_item_props1.csv')
item_props2 = pd.read_csv('sampled_item_props2.csv')
category_tree = pd.read_csv('sampled_category_tree.csv')

"""Combine item properties (part1 and part2)

"""

item_properties = pd.concat([item_props1, item_props2])
item_properties.drop_duplicates(inplace=True)

print("events columns:", events.columns.tolist())
print("item_props1 columns:", item_props1.columns.tolist())
print("item_props2 columns:", item_props2.columns.tolist())
print("category_tree columns:", category_tree.columns.tolist())

""" Convert timestamps to datetime"""

events['datetime'] = pd.to_datetime(events['timestamp'], unit='ms')
item_properties['datetime'] = pd.to_datetime(item_properties['timestamp'], unit='ms')

print(events[['timestamp', 'datetime']].head(10))
print(item_properties[['timestamp', 'datetime']].head(10))

"""Filter only the 'buy' events (collaborative filtering is usually based on purchases)

"""

purchase_events = events[events['event'] == 'transaction']

plt.figure(figsize=(12, 5))
events['datetime'].dt.date.value_counts().sort_index().plot()
plt.title('Event Frequency Over Time')
plt.xlabel('Date')
plt.ylabel('Number of Events')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

event_views = events[events['event'] == 'view']
most_viewed = event_views['itemid'].value_counts().head(20)
plt.figure(figsize=(12, 6))
sns.barplot(x=most_viewed.index.astype(str), y=most_viewed.values, palette='magma')
plt.title('Top 20 Most Viewed Products')
plt.xlabel('Item ID')
plt.ylabel('View Count')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

events['session'] = events.groupby('visitorid')['datetime'].diff().dt.total_seconds().fillna(0)
plt.figure(figsize=(10, 5))
sns.histplot(events['session'], bins=100, kde=True)
plt.title('Distribution of Session Gaps (seconds)')
plt.xlabel('Time Since Last Event (s)')
plt.ylabel('Frequency')
plt.tight_layout()
plt.show()

category_features = item_properties[item_properties['property'] == 'categoryid']
top_categories = category_features['value'].value_counts().head(15)
plt.figure(figsize=(12, 6))
sns.barplot(x=top_categories.index.astype(str), y=top_categories.values, palette='Set2')
plt.title('Top 15 Most Popular Categories')
plt.xlabel('Category ID')
plt.ylabel('Occurrences')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""most popular products"""

top_products = purchase_events['itemid'].value_counts().reset_index()
top_products.columns = ['itemid', 'purchase_count']

plt.figure(figsize=(12, 6))
sns.barplot(data=top_products.head(20), x='itemid', y='purchase_count', palette='viridis')
plt.title('Top 20 Most Purchased Products')
plt.xlabel('Item ID')
plt.ylabel('Number of Purchases')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""Filter for relevant content-based properties"""

content_features = item_properties[item_properties['property'].isin(['categoryid', 'available'])]

"""Pivot the item properties into a feature matrix (itemid x property)

"""

content_features_pivot = content_features.pivot_table(index='itemid',
                                                      columns='property',
                                                      values='value',
                                                      aggfunc='first')

"""Merge with top_products to keep only products with purchase history

"""

content_features_merged = top_products.merge(content_features_pivot, on='itemid', how='left')

"""Fill missing values (if any)

"""

content_features_merged.fillna('unknown', inplace=True)

""" Encode categorical values (e.g., categoryid)

"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
content_features_merged['categoryid'] = le.fit_transform(content_features_merged['categoryid'].astype(str))
content_features_merged['available'] = le.fit_transform(content_features_merged['available'].astype(str))

""" Final content-based features"""

item_content_matrix = content_features_merged[['itemid', 'categoryid', 'available']]

"""Collaborative filtering matrix: User-Item interactions

"""

user_item_matrix = purchase_events.groupby(['visitorid', 'itemid']).size().unstack(fill_value=0)

plt.figure(figsize=(8, 6))
sns.heatmap(user_item_matrix.iloc[:20, :20], cmap='YlGnBu', cbar=True)
plt.title('User-Item Interaction Heatmap (Top 20x20)')
plt.xlabel('Item ID')
plt.ylabel('Visitor ID')
plt.tight_layout()
plt.show()

""" --- Collaborative Filtering: Item-Item Similarity ---"""

from sklearn.metrics.pairwise import cosine_similarity

# Compute cosine similarity between items
item_similarity = cosine_similarity(user_item_matrix.T)
item_similarity_df = pd.DataFrame(item_similarity, index=user_item_matrix.columns, columns=user_item_matrix.columns)

def get_collaborative_recommendations(user_id, num_recommendations=5):
    if user_id not in user_item_matrix.index:
        return []

    user_ratings = user_item_matrix.loc[user_id]
    user_rated_items = user_ratings[user_ratings > 0].index

    scores = item_similarity_df[user_rated_items].sum(axis=1)
    scores = scores.drop(labels=user_rated_items)
    top_items = scores.sort_values(ascending=False).head(num_recommendations).index.tolist()
    return top_items

"""--- Content-Based Filtering: Feature Similarity ---"""

content_matrix = item_content_matrix.set_index('itemid')
content_sim = cosine_similarity(content_matrix)
content_sim_df = pd.DataFrame(content_sim, index=content_matrix.index, columns=content_matrix.index)

def get_content_recommendations(item_id, num_recommendations=5):
    if item_id not in content_sim_df.index:
        return []
    similar_items = content_sim_df[item_id].sort_values(ascending=False)
    similar_items = similar_items.drop(item_id)
    return similar_items.head(num_recommendations).index.tolist()

"""--- Hybrid Recommendation: Combine Scores ---"""

def get_hybrid_recommendations(user_id, alpha=0.5, num_recommendations=5):
    if user_id not in user_item_matrix.index:
        return []

    user_ratings = user_item_matrix.loc[user_id]
    user_rated_items = user_ratings[user_ratings > 0].index

    collab_scores = item_similarity_df[user_rated_items].sum(axis=1)
    content_scores = content_sim_df[user_rated_items].sum(axis=1)

    hybrid_scores = alpha * collab_scores + (1 - alpha) * content_scores
    hybrid_scores = hybrid_scores.drop(labels=user_rated_items, errors='ignore')

    top_items = hybrid_scores.sort_values(ascending=False).head(num_recommendations).index.tolist()
    return top_items

import pickle





import pickle

with open('user_item_matrix.pkl', 'rb') as f:
    user_item_matrix = pickle.load(f)

with open('item_similarity_df.pkl', 'rb') as f:
    item_similarity_df = pickle.load(f)

with open('content_sim_df.pkl', 'rb') as f:
    content_sim_df = pickle.load(f)



